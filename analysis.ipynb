{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy.distance import vincenty\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Turn off chained assignment warning\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = 'inputs/'\n",
    "OUTPUT_PATH = 'outputs_1/'\n",
    "\n",
    "\n",
    "class Data(object):\n",
    "    pass\n",
    "\n",
    "results = Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flood_data = pd.read_csv(INPUT_PATH + '311_2015_flooding.csv', parse_dates=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flood_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flood_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flood_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.n_311_flooding_reports = flood_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of reports of flooding per day required to qualify that day as part of a storm period\n",
    "storm_period_threshold = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many days of the year have flooding data?\n",
    "flood_data.created_date.dt.dayofyear.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_location():\n",
    "    \n",
    "    data = flood_data#[flood_data.created_date.dt.weekofyear == day_of_year]\n",
    "    \n",
    "    plt.plot(data.latitude, data.longitude, '.', alpha=0.1)\n",
    "\n",
    "plot_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_flood_reports(self):\n",
    "    # NB A couple days might be missing from this plot because they had zero reports of flooding\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    plt.plot(self.flood_data.groupby(self.flood_data.created_date.dt.dayofyear).size(), '.-')\n",
    "    plt.axhline(self.storm_period_threshold, color='black', linestyle='dashed')\n",
    "    plt.xlabel('Day of year')\n",
    "    plt.xlim(0, 365)\n",
    "    plt.ylabel('Number of flooding reports')\n",
    "    plt.savefig('flood_reports.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_flood_reports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_storm_periods():\n",
    "    \"\"\"\n",
    "    In the first step, consecutive days with more than {storm_period_threshold} reports of flooding were classed as\n",
    "    storm periods. For {data_year}, we identified {number_of_storm_periods} storms.\n",
    "    \"\"\"\n",
    "    \n",
    "    is_storm_periods = flood_data.groupby(flood_data.created_date.dt.dayofyear).size() > storm_period_threshold\n",
    "    \n",
    "    storm_periods = defaultdict(list)\n",
    "    i = 0\n",
    "    is_yesterday = False\n",
    "    \n",
    "    for today, is_today in zip(is_storm_periods.index, is_storm_periods):\n",
    "        \n",
    "        # if yesterday was False, a new run is beginning\n",
    "        if not is_today and is_yesterday:\n",
    "            i += 1\n",
    "        \n",
    "        if is_today:\n",
    "            storm_periods[i].append(today)\n",
    "            \n",
    "        is_yesterday = is_today\n",
    "    \n",
    "    results.number_of_storm_periods = len(storm_periods)\n",
    "    return storm_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@add_step\n",
    "def eps_to_miles(self):\n",
    "    \n",
    "    latitude_max = self.flood_data.latitude.max()\n",
    "    latitude_min = self.flood_data.latitude.min()\n",
    "    longitude_max = self.flood_data.longitude.max()\n",
    "    longitude_min = self.flood_data.longitude.min()\n",
    "    \n",
    "    #print(list(zip((latitude_max, longitude_min), \n",
    "    #         (latitude_min, longitude_min), \n",
    "    #         (latitude_max, longitude_min), \n",
    "    #         (latitude_max, longitude_max))))\n",
    "    \n",
    "    #plt.plot(*list(zip(\n",
    "    #         (latitude_max, longitude_min), \n",
    "    #         (latitude_min, longitude_min), \n",
    "    #         (latitude_max, longitude_min), \n",
    "    #         (latitude_max, longitude_max))), '.')\n",
    "    #plt.xlabel('latitude')\n",
    "    #plt.ylabel('longitude')\n",
    "    \n",
    "    distance_lat_miles = vincenty((latitude_max, longitude_min), (latitude_min, longitude_min)).miles\n",
    "    distance_lat_units = latitude_max - latitude_min\n",
    "    \n",
    "    distance_long_miles = vincenty((latitude_max, longitude_min), (latitude_max, longitude_max)).miles\n",
    "    distance_long_units = longitude_max - longitude_min\n",
    "    \n",
    "    self.miles_per_deg_lat = distance_lat_miles/distance_lat_units\n",
    "    self.miles_per_deg_long = distance_long_miles/distance_long_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@add_step\n",
    "def cluster_storms_tune_eps(self):\n",
    "\n",
    "    self.n_floods_by_eps = []\n",
    "    self.n_outliers_by_eps = []\n",
    "    self.eps_range = np.arange(0.00001, 0.050, 0.001)\n",
    "    \n",
    "    for eps in self.eps_range:\n",
    "    \n",
    "        self.cluster_storms(eps)\n",
    "        self.n_outliers_by_eps.append(self.n_outliers)\n",
    "        self.n_floods_by_eps.append(self.n_floods)\n",
    "\n",
    "    self.eps_range_miles = self.miles_per_deg_lat * self.eps_range\n",
    "\n",
    "@add_step\n",
    "def plot_n_floods_n_outliers_by_eps(self):\n",
    "    \n",
    "    plt.plot(self.eps_range_miles, self.n_floods_by_eps)\n",
    "    plt.xlabel('Neighborhood radius in miles*')\n",
    "    plt.ylabel('Number of flood clusters')\n",
    "    plt.axvline(0.25, linestyle='dashed', color='black')\n",
    "    plt.twinx()\n",
    "    # spoof a line to get the label added to the legend\n",
    "    plt.plot(np.nan, label='Flood clusters')\n",
    "    plt.plot(self.eps_range_miles, self.n_outliers_by_eps, color='green', label='Outliers')\n",
    "    plt.ylabel('Number of outlier points')\n",
    "    plt.legend()\n",
    "    plt.savefig('n_floods_n_outliers_by_esp.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluster_attributes(cluster):\n",
    "    \n",
    "    latitude_max = cluster.latitude.max()\n",
    "    latitude_min = cluster.latitude.min()\n",
    "    longitude_max = cluster.longitude.max()\n",
    "    longitude_min = cluster.longitude.min()\n",
    "    \n",
    "    space_diameter = vincenty((latitude_max, longitude_min), (latitude_min, longitude_max)).miles    \n",
    "   \n",
    "    time_diameter = cluster.created_date.max() - cluster.created_date.min()\n",
    "    \n",
    "    time_start = cluster.created_date.min()\n",
    "    time_end = cluster.created_date.max()\n",
    "    \n",
    "    space_center_latitude = cluster.latitude.mean()\n",
    "    space_center_longitude = cluster.longitude.mean()    \n",
    "\n",
    "    return [time_start, time_end, space_center_latitude, space_center_longitude,\n",
    "            space_diameter, time_diameter, cluster.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluster_storms(eps):\n",
    "    \n",
    "    self.floods = []\n",
    "    self.eps = eps\n",
    "    self.minimum_flood_reports = 3\n",
    "    self.n_outliers = 0\n",
    "    \n",
    "    for storm_number, storm_days in self.storm_periods.items():\n",
    "        \n",
    "        storm_floods = self.flood_data[self.flood_data.created_date.dt.dayofyear.isin(set(storm_days))]\n",
    "        storm_floods_matrix = storm_floods[['latitude', 'longitude']].as_matrix()\n",
    "        \n",
    "        #print(storm_floods_matrix)\n",
    "        dbscan = DBSCAN(eps=self.eps, min_samples=self.minimum_flood_reports)\n",
    "        \n",
    "        storm_floods['cluster'] = dbscan.fit_predict(storm_floods_matrix)\n",
    "        \n",
    "        is_outlier = (storm_floods.cluster == -1)\n",
    "        self.n_outliers += is_outlier.sum()\n",
    "        storm_floods = storm_floods[~is_outlier]\n",
    "        \n",
    "        floods = list(storm_floods.groupby('cluster').apply(cluster_attributes).values)\n",
    "        floods = [flood + [storm_number] for flood in floods]\n",
    "        #print(floods)\n",
    "        self.floods.extend(floods)\n",
    "    \n",
    "    \n",
    "    self.floods = pd.DataFrame(self.floods,\n",
    "             columns=['time_start', 'time_end', 'latitude_center', 'longitude_center',\n",
    "                     'diameter', 'duration', 'number_of_reports', 'storm_number'])\n",
    "    self.n_floods = len(self.floods)\n",
    "    \n",
    "    return floods, n_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e.get_storm_periods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e.cluster_storms_tune_eps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e.eps_to_miles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e.plot_n_floods_n_outliers_by_eps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e.cluster_storms(0.25/e.miles_per_deg_long)\n",
    "e.n_floods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(e.flood_data['longitude'], e.flood_data['latitude'], '.', alpha=0.2)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.savefig('flood_reports_by_location.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(e.floods['longitude_center'], e.floods['latitude_center'], 'x', alpha=0.8)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.savefig('flood_clusters_by_location.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#e.eps_to_miles()\n",
    "#e.get_storm_periods()\n",
    "e.cluster_storms(0.004)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
